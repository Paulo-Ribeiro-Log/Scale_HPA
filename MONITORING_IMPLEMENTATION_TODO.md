# TODO: Implementa√ß√£o Correta do Sistema de Monitoring HPA-Watchdog

**Data:** 05 de novembro de 2025
**Status:** üî¥ Implementa√ß√£o Incorreta - Requer Refatora√ß√£o Completa

---

## üéØ Objetivo

Implementar sistema de monitoramento de HPAs em tempo real com:
- Port-forward persistente para Prometheus
- Coleta hist√≥rica de 3 dias antes de iniciar monitoramento
- Baseline de dados para compara√ß√£o e detec√ß√£o de anomalias
- Gerenciamento correto de portas com cleanup no shutdown

---

## ‚ùå Problemas da Implementa√ß√£o Atual

### 1. Port-Forward Ef√™mero (ERRADO)
**Problema:** Port-forward √© criado e destru√≠do a cada scan (linhas 373-389 de `engine.go`)
```go
// ATUAL (ERRADO)
if err := e.pfManager.Start(target.Cluster); err != nil { ... }
func() {
    defer func() {
        if err := e.pfManager.Stop(target.Cluster); err != nil { ... }
    }()
    // ... scan ...
}()
```

**Por que est√° errado:**
- Port-forward √© destru√≠do ap√≥s cada coleta (1 minuto)
- Overhead de criar/destruir conex√£o kubectl a cada scan
- Imposs√≠vel manter duas portas simult√¢neas
- Portas ficam √≥rf√£s se aplica√ß√£o crashar durante scan

### 2. Sem Coleta Hist√≥rica de Baseline
**Problema:** Monitoramento inicia IMEDIATAMENTE ao adicionar HPA
- N√£o h√° dados hist√≥ricos de 3 dias para compara√ß√£o
- Detec√ß√£o de anomalias √© imposs√≠vel sem baseline
- Sistema n√£o tem contexto de comportamento normal do HPA

### 3. Gerenciamento de Portas Incorreto
**Problema:** L√≥gica de portas √≠mpares/pares n√£o funciona como fila alternada
- Port-forward √© destru√≠do antes de alternar para pr√≥ximo cluster
- Imposs√≠vel ter 2 portas abertas simultaneamente
- N√£o h√° altern√¢ncia real entre portas 55553 e 55554

### 4. Cleanup Inadequado
**Problema:** Port-forwards √≥rf√£os quando servidor crashar
- Destrui√ß√£o de porta acontece durante scan (goroutine pode n√£o completar)
- N√£o h√° cleanup garantido no shutdown do servidor
- `StopAll()` √© chamado mas pode n√£o executar se servidor crashar

---

## ‚úÖ Arquitetura Correta a Implementar

### Fase 1: Port-Forward Persistente

**Objetivo:** Port-forward vive durante toda execu√ß√£o do servidor, n√£o por scan.

#### 1.1. Altera√ß√µes em `engine.go`

**Remover:** Cria√ß√£o/destrui√ß√£o de port-forward no `runScan()` (linhas 373-389)

**Adicionar:** Port-forward persistente no `Start()` e `Stop()`

```go
// Start inicia scan engine COM port-forwards persistentes
func (e *ScanEngine) Start() error {
    e.mu.Lock()
    if e.running {
        e.mu.Unlock()
        return nil
    }
    e.running = true
    e.paused = false
    e.mu.Unlock()

    log.Info().
        Str("mode", e.config.Mode.String()).
        Dur("interval", e.config.Interval).
        Dur("duration", e.config.Duration).
        Msg("Iniciando scan engine")

    // NOVO: Inicia port-forwards PERSISTENTES para todos os clusters
    // Agrupa clusters por porta (√≠mpar/par)
    clustersByPort := e.groupClustersByPort()

    // Inicia port-forwards nas 2 portas SIMULTANEAMENTE
    for port, clusters := range clustersByPort {
        for _, cluster := range clusters {
            if err := e.pfManager.Start(cluster); err != nil {
                log.Error().
                    Err(err).
                    Str("cluster", cluster).
                    Int("port", port).
                    Msg("Falha ao iniciar port-forward persistente")
                // Continua com outros clusters
            } else {
                log.Info().
                    Str("cluster", cluster).
                    Int("port", port).
                    Msg("Port-forward persistente iniciado")
            }
        }
    }

    // Se modo stress test, captura baseline antes de iniciar
    if e.config.Mode == scanner.ScanModeStressTest {
        if err := e.captureBaseline(); err != nil {
            log.Error().
                Err(err).
                Msg("Falha ao capturar baseline, continuando sem baseline")
        }
    }

    // Inicia loop de scan (SEM criar/destruir port-forwards)
    e.wg.Add(1)
    go e.scanLoop()

    return nil
}

// Stop para scan engine E port-forwards persistentes
func (e *ScanEngine) Stop() error {
    e.mu.Lock()
    if !e.running {
        e.mu.Unlock()
        return nil
    }
    e.running = false
    e.mu.Unlock()

    log.Info().Msg("Parando scan engine")

    // Cancela contexto (para scanLoop)
    e.cancel()

    // Aguarda scanLoop terminar
    e.wg.Wait()

    // NOVO: Para TODOS os port-forwards persistentes
    log.Info().Msg("Parando todos os port-forwards persistentes...")
    if err := e.pfManager.StopAll(); err != nil {
        log.Error().Err(err).Msg("Erro ao parar port-forwards")
    } else {
        log.Info().Msg("Todos os port-forwards parados com sucesso")
    }

    // Se modo stress test, finaliza e salva resultado
    if e.config.Mode == scanner.ScanModeStressTest {
        if err := e.finalizeStressTest(); err != nil {
            log.Error().
                Err(err).
                Msg("Erro ao finalizar stress test")
        }
    }

    // Cleanup e fecha persist√™ncia
    if e.persistence != nil {
        if err := e.persistence.Cleanup(); err != nil {
            log.Warn().Err(err).Msg("Erro ao limpar dados antigos")
        }
        if err := e.persistence.Close(); err != nil {
            log.Warn().Err(err).Msg("Erro ao fechar banco de dados")
        }
        log.Info().Msg("Persist√™ncia SQLite fechada")
    }

    log.Info().Msg("Scan engine parado completamente")
    return nil
}

// groupClustersByPort agrupa clusters por porta (√≠mpar/par)
func (e *ScanEngine) groupClustersByPort() map[int][]string {
    result := map[int][]string{
        55553: {}, // Porta √≠mpar
        55554: {}, // Porta par
    }

    for i, target := range e.config.Targets {
        port := 55554 // Par (padr√£o)
        if i%2 == 1 {
            port = 55553 // √çmpar
        }
        result[port] = append(result[port], target.Cluster)
    }

    return result
}
```

**Modificar:** `runScan()` para REUTILIZAR port-forwards existentes

```go
// runScan executa um scan completo (SEM criar/destruir port-forwards)
func (e *ScanEngine) runScan() {
    log.Info().Msg("Executando scan...")

    scanStart := time.Now()

    // Para cada target configurado
    for _, target := range e.config.Targets {
        log.Info().
            Str("cluster", target.Cluster).
            Strs("namespaces", target.Namespaces).
            Msg("Escaneando cluster")

        // NOVO: REUTILIZA port-forward existente (n√£o cria/destroi)
        promEndpoint := e.pfManager.GetURL(target.Cluster)
        if promEndpoint == "" {
            log.Warn().
                Str("cluster", target.Cluster).
                Msg("Port-forward n√£o dispon√≠vel, pulando cluster")
            continue
        }

        // Cria contexto com timeout para o scan
        ctx, cancel := context.WithTimeout(e.ctx, 2*time.Minute)

        // Cria ClusterInfo
        context := target.Cluster
        if !strings.HasSuffix(target.Cluster, "-admin") {
            context = target.Cluster + "-admin"
        }

        clusterInfo := &models.ClusterInfo{
            Name:    target.Cluster,
            Context: context,
        }

        // Cria collector para este cluster
        collector, err := monitor.NewCollector(clusterInfo, promEndpoint, &monitor.CollectorConfig{
            ScanInterval:      e.config.Interval,
            ExcludeNamespaces: []string{},
            EnablePrometheus:  true,
        })
        if err != nil {
            log.Error().
                Err(err).
                Str("cluster", target.Cluster).
                Msg("Falha ao criar collector")
            cancel()
            continue
        }

        // Executa scan do cluster
        result, err := collector.Scan(ctx)
        cancel()

        if err != nil {
            log.Error().
                Err(err).
                Str("cluster", target.Cluster).
                Msg("Falha ao executar scan")
            continue
        }

        // ... resto do c√≥digo de processamento de snapshots ...

        log.Info().
            Str("cluster", target.Cluster).
            Int("snapshots", result.SnapshotsCount).
            Int("anomalies", len(result.Anomalies)).
            Int("errors", len(result.Errors)).
            Msg("Cluster escaneado com sucesso")
    }

    scanDuration := time.Since(scanStart)
    log.Info().
        Dur("duration", scanDuration).
        Msg("Scan completo")
}
```

#### 1.2. Altera√ß√µes em `portforward.go`

**Adicionar:** Verifica√ß√£o de sa√∫de do port-forward antes de cada scan

```go
// EnsureRunning verifica e reinicia port-forward se necess√°rio
func (pf *PortForward) EnsureRunning() error {
    if pf.IsRunning() {
        return nil // J√° est√° rodando
    }

    log.Warn().
        Str("cluster", pf.cluster).
        Msg("Port-forward inativo, reiniciando...")

    return pf.Start()
}
```

**Modificar:** `PortForwardManager.Start()` para n√£o parar port-forward anterior

```go
// Start inicia port-forward para um cluster (PERSISTENTE)
func (m *PortForwardManager) Start(cluster string) error {
    // Se j√° existe E est√° rodando, retorna
    if pf, exists := m.forwards[cluster]; exists {
        if pf.IsRunning() {
            log.Info().Str("cluster", cluster).Msg("Port-forward j√° ativo")
            return nil
        }
        // Se existe mas n√£o est√° rodando, remove e recria
        log.Warn().Str("cluster", cluster).Msg("Port-forward existe mas n√£o est√° ativo, recriando...")
        pf.Stop()
        delete(m.forwards, cluster)
    }

    // Atribui √≠ndice ao cluster se ainda n√£o tem
    if _, exists := m.clusterIndex[cluster]; !exists {
        m.clusterIndex[cluster] = len(m.clusterIndex)
    }
    index := m.clusterIndex[cluster]

    // Determina porta baseado no √≠ndice (√≠mpar/par)
    var port int
    if index%2 == 0 {
        port = m.portEven // 55554
    } else {
        port = m.portOdd // 55553
    }

    // REMOVIDO: L√≥gica de waitForRelease (n√£o precisamos mais parar port-forward anterior)

    // Descobre o nome do servi√ßo Prometheus
    serviceName := m.discoverPrometheusService(cluster)

    log.Info().
        Str("cluster", cluster).
        Int("index", index).
        Int("port", port).
        Str("service", serviceName).
        Msg("Iniciando port-forward persistente")

    // Context precisa do sufixo -admin
    context := cluster
    if !strings.HasSuffix(cluster, "-admin") {
        context = cluster + "-admin"
    }

    pf := New(Config{
        Cluster:   context,
        Service:   serviceName,
        LocalPort: port,
    })

    if err := pf.Start(); err != nil {
        return fmt.Errorf("falha ao iniciar port-forward: %w", err)
    }

    m.forwards[cluster] = pf

    log.Info().
        Str("cluster", cluster).
        Int("port", port).
        Msg("Port-forward persistente ativo")

    return nil
}
```

---

### Fase 2: Coleta Hist√≥rica de Baseline (3 dias)

**Objetivo:** Coletar dados hist√≥ricos de 3 dias do HPA ANTES de iniciar monitoramento real.

#### 2.1. Nova Fun√ß√£o em `monitor/collector.go`

```go
// CollectHistoricalData coleta dados hist√≥ricos de um HPA via Prometheus
func (c *Collector) CollectHistoricalData(ctx context.Context, namespace, hpaName string, duration time.Duration) ([]*models.HPASnapshot, error) {
    log.Info().
        Str("namespace", namespace).
        Str("hpa", hpaName).
        Dur("duration", duration).
        Msg("Coletando dados hist√≥ricos do Prometheus")

    // Query Prometheus para dados hist√≥ricos
    // Range query: √∫ltimos 3 dias com step de 5 minutos
    step := 5 * time.Minute
    endTime := time.Now()
    startTime := endTime.Add(-duration)

    // Queries Prometheus para m√©tricas hist√≥ricas
    queries := map[string]string{
        "cpu_current": fmt.Sprintf(
            `avg(rate(container_cpu_usage_seconds_total{namespace="%s",pod=~"%s-.*"}[5m])) * 100`,
            namespace, hpaName,
        ),
        "memory_current": fmt.Sprintf(
            `avg(container_memory_working_set_bytes{namespace="%s",pod=~"%s-.*"}) / 1024 / 1024`,
            namespace, hpaName,
        ),
        "replicas": fmt.Sprintf(
            `kube_deployment_status_replicas{namespace="%s",deployment="%s"}`,
            namespace, hpaName,
        ),
    }

    snapshots := make([]*models.HPASnapshot, 0)

    // Para cada timestamp no range (step de 5 minutos)
    for ts := startTime; ts.Before(endTime); ts = ts.Add(step) {
        snapshot := &models.HPASnapshot{
            Cluster:   c.clusterInfo.Name,
            Namespace: namespace,
            Name:      hpaName,
            Timestamp: ts,
        }

        // Executar queries para este timestamp
        for metric, query := range queries {
            value, err := c.prometheusClient.QueryAtTime(ctx, query, ts)
            if err != nil {
                log.Debug().
                    Err(err).
                    Str("metric", metric).
                    Time("timestamp", ts).
                    Msg("Falha ao coletar m√©trica hist√≥rica")
                continue
            }

            // Preencher snapshot com valores
            switch metric {
            case "cpu_current":
                snapshot.CPUCurrent = value
            case "memory_current":
                snapshot.MemoryCurrent = value
            case "replicas":
                snapshot.CurrentReplicas = int32(value)
            }
        }

        snapshots = append(snapshots, snapshot)
    }

    log.Info().
        Str("namespace", namespace).
        Str("hpa", hpaName).
        Int("snapshots_collected", len(snapshots)).
        Msg("Dados hist√≥ricos coletados com sucesso")

    return snapshots, nil
}
```

#### 2.2. Nova Fase de Inicializa√ß√£o em `handlers/monitoring.go`

```go
// AddHPA adiciona um HPA espec√≠fico para monitoramento
// POST /api/v1/monitoring/hpa
// Body: { "cluster": "...", "namespace": "...", "hpa": "..." }
func (h *MonitoringHandler) AddHPA(c *gin.Context) {
    var req struct {
        Cluster   string `json:"cluster" binding:"required"`
        Namespace string `json:"namespace" binding:"required"`
        HPA       string `json:"hpa" binding:"required"`
    }

    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{
            "status":  "error",
            "message": "Invalid request body",
            "error":   err.Error(),
        })
        return
    }

    // Remove sufixo -admin do cluster
    clusterName := strings.TrimSuffix(req.Cluster, "-admin")

    log.Info().
        Str("cluster_received", req.Cluster).
        Str("cluster_normalized", clusterName).
        Str("namespace", req.Namespace).
        Str("hpa", req.HPA).
        Msg("Adicionando HPA ao monitoramento")

    // NOVO: Verificar se HPA j√° tem baseline (dados hist√≥ricos)
    hasBaseline, err := h.checkHPABaseline(clusterName, req.Namespace, req.HPA)
    if err != nil {
        log.Warn().Err(err).Msg("Erro ao verificar baseline do HPA")
    }

    if !hasBaseline {
        log.Info().
            Str("cluster", clusterName).
            Str("namespace", req.Namespace).
            Str("hpa", req.HPA).
            Msg("HPA sem baseline, iniciando coleta hist√≥rica de 3 dias...")

        // Inicia coleta hist√≥rica em background
        go h.collectHistoricalDataForHPA(clusterName, req.Namespace, req.HPA)
    }

    // Criar target com HPA espec√≠fico
    target := scanner.ScanTarget{
        Cluster:    clusterName,
        Namespaces: []string{req.Namespace},
        HPAs:       []string{req.HPA},
    }

    h.engine.AddTarget(target)

    c.JSON(200, gin.H{
        "status":       "success",
        "message":      "HPA added to monitoring successfully",
        "has_baseline": hasBaseline,
        "target": gin.H{
            "cluster":   clusterName,
            "namespace": req.Namespace,
            "hpa":       req.HPA,
        },
    })
}

// checkHPABaseline verifica se HPA j√° tem dados hist√≥ricos no SQLite
func (h *MonitoringHandler) checkHPABaseline(cluster, namespace, hpa string) (bool, error) {
    cache := h.engine.GetCache()
    if cache == nil {
        return false, fmt.Errorf("cache not available")
    }

    // Verifica se existe dados de pelo menos 2 dias atr√°s
    tsData := cache.Get(cluster, namespace, hpa)
    if tsData == nil {
        return false, nil
    }

    twoDaysAgo := time.Now().Add(-48 * time.Hour)

    tsData.RLock()
    defer tsData.RUnlock()

    for _, snapshot := range tsData.Snapshots {
        if snapshot.Timestamp.Before(twoDaysAgo) {
            // Tem dados de 2 dias atr√°s, consideramos como baseline v√°lida
            return true, nil
        }
    }

    return false, nil
}

// collectHistoricalDataForHPA coleta dados hist√≥ricos de 3 dias em background
func (h *MonitoringHandler) collectHistoricalDataForHPA(cluster, namespace, hpa string) {
    log.Info().
        Str("cluster", cluster).
        Str("namespace", namespace).
        Str("hpa", hpa).
        Msg("Iniciando coleta hist√≥rica de 3 dias em background")

    // Aguardar port-forward estar dispon√≠vel
    maxRetries := 30
    promEndpoint := ""

    // TODO: Implementar acesso ao pfManager do engine
    // Por enquanto, assume que port-forward est√° ativo ap√≥s 10s
    time.Sleep(10 * time.Second)

    // Criar collector tempor√°rio para coleta hist√≥rica
    // ... (implementa√ß√£o usando CollectHistoricalData)

    log.Info().
        Str("cluster", cluster).
        Str("namespace", namespace).
        Str("hpa", hpa).
        Msg("Coleta hist√≥rica de 3 dias conclu√≠da")
}
```

---

### Fase 3: Gerenciamento Correto de Portas (Fila Alternada)

**Objetivo:** Duas portas abertas simultaneamente, leitura alternada entre clusters.

#### 3.1. Altera√ß√µes em `scanner/scan.go` (NOVO)

```go
// PortQueue gerencia fila de clusters por porta
type PortQueue struct {
    port55553 []string  // Clusters na porta √≠mpar
    port55554 []string  // Clusters na porta par
    current   int       // √çndice atual na leitura alternada
    mu        sync.RWMutex
}

// NewPortQueue cria nova fila de portas
func NewPortQueue() *PortQueue {
    return &PortQueue{
        port55553: make([]string, 0),
        port55554: make([]string, 0),
        current:   0,
    }
}

// AddCluster adiciona cluster √† fila apropriada (baseado em √≠ndice)
func (pq *PortQueue) AddCluster(cluster string, index int) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    if index%2 == 0 {
        pq.port55554 = append(pq.port55554, cluster)
    } else {
        pq.port55553 = append(pq.port55553, cluster)
    }
}

// GetNextCluster retorna pr√≥ximo cluster a ser lido (alternando portas)
func (pq *PortQueue) GetNextCluster() (string, int) {
    pq.mu.Lock()
    defer pq.mu.Unlock()

    // Alterna entre porta √≠mpar e par
    if pq.current%2 == 0 {
        // Ler porta 55553 (√≠mpar)
        if len(pq.port55553) > 0 {
            clusterIndex := pq.current / 2
            if clusterIndex >= len(pq.port55553) {
                pq.current = 0
                clusterIndex = 0
            }
            cluster := pq.port55553[clusterIndex]
            pq.current++
            return cluster, 55553
        }
    } else {
        // Ler porta 55554 (par)
        if len(pq.port55554) > 0 {
            clusterIndex := pq.current / 2
            if clusterIndex >= len(pq.port55554) {
                pq.current = 1
                clusterIndex = 0
            }
            cluster := pq.port55554[clusterIndex]
            pq.current++
            return cluster, 55554
        }
    }

    // Se chegou aqui, reseta e tenta novamente
    pq.current = 0
    return pq.GetNextCluster()
}
```

#### 3.2. Modificar `engine.go` para usar PortQueue

```go
// ScanEngine orquestra coleta, an√°lise e detec√ß√£o
type ScanEngine struct {
    config *scanner.ScanConfig

    // Componentes
    pfManager   *portforward.PortForwardManager
    portQueue   *scanner.PortQueue  // NOVO: Fila de portas alternadas
    cache       *storage.TimeSeriesCache
    persistence *storage.Persistence
    detector    *analyzer.Detector

    // ... resto dos campos ...
}

// runScan executa um scan completo COM leitura alternada de portas
func (e *ScanEngine) runScan() {
    log.Info().Msg("Executando scan com leitura alternada de portas...")

    scanStart := time.Now()

    // NOVO: Ler clusters alternando entre portas
    clustersToScan := len(e.config.Targets)

    for i := 0; i < clustersToScan; i++ {
        cluster, port := e.portQueue.GetNextCluster()

        log.Info().
            Str("cluster", cluster).
            Int("port", port).
            Msg("Escaneando cluster (leitura alternada)")

        target := e.findTargetByCluster(cluster)
        if target == nil {
            continue
        }

        // Reutiliza port-forward existente
        promEndpoint := e.pfManager.GetURL(cluster)
        if promEndpoint == "" {
            log.Warn().
                Str("cluster", cluster).
                Int("port", port).
                Msg("Port-forward n√£o dispon√≠vel, pulando cluster")
            continue
        }

        // ... resto do c√≥digo de scan ...
    }

    scanDuration := time.Since(scanStart)
    log.Info().
        Dur("duration", scanDuration).
        Msg("Scan completo")
}
```

---

### Fase 4: Cleanup Garantido no Shutdown

**Objetivo:** Port-forwards s√£o destru√≠dos APENAS quando servidor web para.

#### 4.1. Altera√ß√µes em `server.go`

```go
// Run inicia servidor web COM cleanup garantido
func (s *Server) Run(ctx context.Context, foreground bool) error {
    // ... c√≥digo existente ...

    // NOVO: Registrar handler de shutdown para cleanup de port-forwards
    go func() {
        <-ctx.Done()
        log.Info().Msg("Contexto cancelado, iniciando shutdown...")

        // Para monitoring engine (que para port-forwards)
        if s.monitoringEngine != nil {
            log.Info().Msg("Parando monitoring engine e port-forwards...")
            if err := s.monitoringEngine.Stop(); err != nil {
                log.Error().Err(err).Msg("Erro ao parar monitoring engine")
            } else {
                log.Info().Msg("Monitoring engine e port-forwards parados com sucesso")
            }
        }

        // Para servidor HTTP
        shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
        defer cancel()

        if err := s.httpServer.Shutdown(shutdownCtx); err != nil {
            log.Error().Err(err).Msg("Erro ao parar servidor HTTP")
        } else {
            log.Info().Msg("Servidor HTTP parado com sucesso")
        }
    }()

    // ... resto do c√≥digo ...
}
```

---

## üìã Checklist de Implementa√ß√£o

### ‚úÖ Fase 1: Port-Forward Persistente
- [ ] Remover cria√ß√£o/destrui√ß√£o de port-forward em `runScan()`
- [ ] Adicionar cria√ß√£o de port-forwards em `engine.Start()`
- [ ] Adicionar destrui√ß√£o de port-forwards em `engine.Stop()`
- [ ] Implementar `groupClustersByPort()` para separar clusters por porta
- [ ] Adicionar verifica√ß√£o de sa√∫de `EnsureRunning()` em portforward.go
- [ ] Modificar `PortForwardManager.Start()` para n√£o parar port-forward anterior
- [ ] Testar: Port-forwards devem permanecer ativos entre scans

### ‚úÖ Fase 2: Coleta Hist√≥rica
- [ ] Implementar `CollectHistoricalData()` em collector.go
- [ ] Adicionar queries Prometheus para range queries (√∫ltimos 3 dias)
- [ ] Implementar `checkHPABaseline()` para verificar dados existentes
- [ ] Implementar `collectHistoricalDataForHPA()` para coleta em background
- [ ] Modificar `AddHPA` handler para iniciar coleta hist√≥rica se necess√°rio
- [ ] Adicionar campo `has_baseline` na resposta da API
- [ ] Salvar dados hist√≥ricos no SQLite
- [ ] Testar: HPA s√≥ inicia monitoramento real ap√≥s ter baseline de 3 dias

### ‚úÖ Fase 3: Gerenciamento de Fila de Portas
- [ ] Criar struct `PortQueue` em scanner/scan.go
- [ ] Implementar `AddCluster()` para adicionar √† fila correta
- [ ] Implementar `GetNextCluster()` para leitura alternada
- [ ] Adicionar `portQueue` no `ScanEngine`
- [ ] Modificar `runScan()` para usar fila alternada
- [ ] Testar: Leitura deve alternar entre porta 55553 e 55554

### ‚úÖ Fase 4: Cleanup no Shutdown
- [ ] Adicionar handler de shutdown em `server.go`
- [ ] Garantir chamada a `monitoringEngine.Stop()` no shutdown
- [ ] Testar: Port-forwards devem ser destru√≠dos ao parar servidor
- [ ] Testar: Port-forwards N√ÉO devem ficar √≥rf√£os ap√≥s crash (usar `defer` ou signal handling)

---

## üß™ Plano de Testes

### Teste 1: Port-Forward Persistente
```bash
# 1. Iniciar servidor
./build/k8s-hpa-manager web -f

# 2. Adicionar 2 HPAs de clusters diferentes
curl -X POST http://localhost:8080/api/v1/monitoring/hpa \
  -H "Authorization: Bearer poc-token-123" \
  -H "Content-Type: application/json" \
  -d '{"cluster":"akspriv-prod-admin","namespace":"prod","hpa":"app1"}'

curl -X POST http://localhost:8080/api/v1/monitoring/hpa \
  -H "Authorization: Bearer poc-token-123" \
  -H "Content-Type: application/json" \
  -d '{"cluster":"akspriv-staging-admin","namespace":"staging","hpa":"app2"}'

# 3. Verificar port-forwards ativos
ps aux | grep "kubectl port-forward"
# Esperado: 2 processos (porta 55553 e 55554)

# 4. Aguardar 2 minutos (2 scans)
sleep 120

# 5. Verificar port-forwards AINDA ativos
ps aux | grep "kubectl port-forward"
# Esperado: 2 processos (mesmos PIDs de antes)

# 6. Parar servidor (Ctrl+C)

# 7. Verificar port-forwards foram destru√≠dos
ps aux | grep "kubectl port-forward"
# Esperado: Nenhum processo
```

### Teste 2: Coleta Hist√≥rica
```bash
# 1. Limpar SQLite
rm ~/.k8s-hpa-manager/monitoring.db

# 2. Iniciar servidor
./build/k8s-hpa-manager web -f

# 3. Adicionar HPA novo (sem baseline)
curl -X POST http://localhost:8080/api/v1/monitoring/hpa \
  -H "Authorization: Bearer poc-token-123" \
  -H "Content-Type: application/json" \
  -d '{"cluster":"akspriv-prod-admin","namespace":"prod","hpa":"app1"}'

# Esperado na resposta:
# {
#   "status": "success",
#   "has_baseline": false,
#   "message": "HPA added, collecting 3 days of historical data..."
# }

# 4. Verificar logs
# Esperado:
# "Iniciando coleta hist√≥rica de 3 dias em background"
# "Coletando dados hist√≥ricos do Prometheus duration=72h"
# "Dados hist√≥ricos coletados com sucesso snapshots_collected=XXX"
# "Coleta hist√≥rica de 3 dias conclu√≠da"

# 5. Consultar SQLite
sqlite3 ~/.k8s-hpa-manager/monitoring.db "SELECT COUNT(*) FROM snapshots WHERE namespace='prod' AND hpa_name='app1';"
# Esperado: ~864 snapshots (3 dias * 24h * 12 snapshots/hora com step de 5min)
```

### Teste 3: Fila Alternada de Portas
```bash
# 1. Adicionar 4 HPAs (2 em cada porta)
# cluster1 -> porta 55554 (par)
# cluster2 -> porta 55553 (√≠mpar)
# cluster3 -> porta 55554 (par)
# cluster4 -> porta 55553 (√≠mpar)

# 2. Monitorar logs durante scan
# Esperado (ordem alternada):
# "Escaneando cluster cluster=cluster2 port=55553"  # Primeiro da porta √≠mpar
# "Escaneando cluster cluster=cluster1 port=55554"  # Primeiro da porta par
# "Escaneando cluster cluster=cluster4 port=55553"  # Segundo da porta √≠mpar
# "Escaneando cluster cluster=cluster3 port=55554"  # Segundo da porta par
```

---

## üìù Notas T√©cnicas

### Port-Forward vs Prometheus Service Discovery

**Por que port-forward e n√£o service discovery direto?**
- Prometheus pode estar em namespace privado (monitoring)
- Port-forward garante acesso via kubectl credentials
- Compat√≠vel com clusters AKS remotos via VPN

### Step de 5 Minutos para Dados Hist√≥ricos

**Por que 5 minutos?**
- 3 dias * 24h * 12 snapshots/hora = ~864 snapshots
- SQLite pode armazenar facilmente (< 1MB por HPA)
- Resolu√ß√£o suficiente para detectar anomalias
- N√£o sobrecarrega Prometheus com queries muito granulares

### Altern√¢ncia de Portas

**Por que alternar?**
- Evita sobrecarga de uma √∫nica porta
- Distribui load de rede entre 2 portas
- Permite paralelismo futuro (ler 2 clusters simultaneamente)
- Reduz chance de timeout por congestionamento

---

## üöÄ Ordem de Implementa√ß√£o Recomendada

1. **Fase 1 primeiro** (Port-Forward Persistente)
   - √â a base para tudo funcionar
   - Sem isso, fases 2 e 3 n√£o funcionam

2. **Fase 2 em paralelo** (Coleta Hist√≥rica)
   - Pode ser implementada independentemente
   - Requer Fase 1 funcionando para testar

3. **Fase 3 depois** (Fila Alternada)
   - Melhoria de performance
   - N√£o bloqueia funcionalidade b√°sica

4. **Fase 4 cont√≠nua** (Cleanup)
   - Implementar desde o in√≠cio
   - Testar a cada fase

---

## ‚ö†Ô∏è Avisos Importantes

1. **N√£o comitar com bugs conhecidos**
   - Sempre testar cada fase completamente
   - Reverter se algo quebrar

2. **Port-forwards √≥rf√£os s√£o problem√°ticos**
   - Podem ocupar porta indefinidamente
   - Sempre garantir cleanup no shutdown
   - Usar `defer` em fun√ß√µes cr√≠ticas

3. **SQLite pode crescer**
   - Implementar cleanup de dados antigos (> 30 dias)
   - Monitorar tamanho do banco

4. **Prometheus pode ficar lento**
   - Range queries de 3 dias podem demorar
   - Implementar timeout adequado (5 minutos)
   - Mostrar progresso na UI

---

**Fim do Documento TODO**
